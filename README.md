# Titanic-Spaceship-Classification-
Second Assignment of Machine Learning Course - 2024
# Spaceship Titanic â€” Classification Project

This repository contains a ready-to-run workflow for the Spaceship Titanic classification challenge. It covers data exploration, preprocessing, feature engineering, model training, evaluation, and generating a Kaggle submission.

- Main notebook: `Titanic_Spaceship_Classification.ipynb`
- Dataset: `@https://www.kaggle.com/competitions/spaceship-titanic/` (Kaggle competition page)

### Project Overview

- Goal: Predict whether a passenger was transported (`Transported`).
- Includes:
  - Exploratory data analysis (EDA)
  - Data cleaning and preprocessing (missing values, encoding, scaling)
  - Feature engineering
  - Baseline and tree-based models
  - Cross-validation and evaluation
  - Creation of `submission.csv` for Kaggle

### Getting the Data

1. Open: `@https://www.kaggle.com/competitions/spaceship-titanic/`
2. Download `train.csv` and `test.csv`
3. Create a `data/` folder in the project root and place the files:
   - `data/train.csv`
   - `data/test.csv`

Note: A Kaggle account is required to download the data.

### Environment Setup

Use Python 3.9+.

- Required packages:
  - pandas
  - numpy
  - scikit-learn
  - matplotlib
  - seaborn
  - jupyter

Using pip:

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install pandas numpy scikit-learn matplotlib seaborn jupyter
```

Using conda:

```bash
conda create -y -n spaceship-titanic python=3.10
conda activate spaceship-titanic
conda install -y pandas numpy scikit-learn matplotlib seaborn jupyter
```

### Running the Notebook

1. Activate the environment
2. Ensure `data/train.csv` and `data/test.csv` exist
3. Launch Jupyter:

```bash
jupyter notebook Titanic_Spaceship_Classification.ipynb
```

4. Run all cells. The notebook will:
   - Load, explore, and preprocess the data
   - Train baseline models (e.g., Logistic Regression, Random Forest, Gradient Boosting)
   - Evaluate models via cross-validation
   - Output `submission.csv` for Kaggle

### Methodology (High-Level)

- Preprocessing:
  - Impute missing values (numeric and categorical)
  - One-hot encode categorical features
  - Scale features when needed for linear models
- Feature Engineering:
  - Parse composite fields (e.g., cabin/deck if present)
  - Add informative binary/interaction features when beneficial
- Modeling:
  - Establish simple baselines
  - Use tree-based models for non-linear patterns
  - Employ cross-validation for robust estimates
- Evaluation:
  - Primary metric: accuracy (as per Kaggle)
  - Use confusion matrix and classification report for insights

### Reproducibility

- Fixed random seeds where applicable
- Single notebook workflow for clarity

### Outputs

- `submission.csv`: Generated by the notebook and ready for Kaggle upload

### Acknowledgments

- Dataset and task: https://www.kaggle.com/competitions/spaceship-titanic/
